Section 1: Critical Questions Answered
Q1: Arti Onion Service Status (Oct 2025)
	•	Answer: Arti (Rust Tor) is not yet fully production-ready for onion services as of Oct 2025. The Tor Project still considers Arti’s onion-service hosting experimental and recommends caution. Key features (DoS defenses, introduction-point auth, etc.) are only partially implemented, and onion hosting is disabled by default[1][2]. In contrast, C Tor’s onion services are battle-tested.
	•	Confidence: High. Tor’s own documentation (Aug 2025) explicitly states Arti shouldn’t be used in production for hosting services[3][1].
	•	Evidence: Arti 1.6 docs list onion services as partially implemented and turned off by default[1]. The official onion service ecosystem matrix (Mar 2025) shows Arti missing some critical features (e.g. stealth auth, PoW defenses) or only partial support[4][5]. Arti maintainers themselves label it “experimental, not recommended for production use”[3].
	•	Recommendation: Use the C Tor daemon for onion services in production. While Arti’s client-side (outbound over Tor) is usable, for running a stable hidden service node we should rely on the proven C Tor. A hybrid approach is possible: use Arti or a Rust SOCKS library for outbound traffic, but run a Tor daemon for the inbound onion service (via Tor’s control port). This ensures reliability and security. We can reevaluate Arti in the future when Tor Project announces onion services as production-ready (likely once Arti implements remaining features and passes security audits). For now, prioritize reliability: go with C Tor.
Q2: Tonic + SOCKS5 Integration Pattern
	•	Answer: Yes, Tonic gRPC can be used with a SOCKS5 proxy by plugging in a custom Hyper connector (using a SOCKS connector crate). The recommended approach is to use hyper-socks2, which wraps a SOCKS5 proxy as a Hyper Service. This has been demonstrated to work with Tonic’s Channel. No fundamental incompatibilities are known; it’s a matter of constructing the channel with the proxy connector.
	•	Confidence: High. We found working examples of Tonic clients using Hyper’s SOCKS connector[6][7] and crates (like Rigetti’s gRPC client) depending on hyper-socks2 alongside Tonic[8][9].
	•	Evidence: A Tonic discussion shows a solution using hyper_socks2::SocksConnector with a HttpConnector. The code sets connector.enforce_http(false) (to allow non-HTTP URIs) and builds a Hyper Client with the SOCKS proxy[7][10]. The gist of the example:
let socks5_addr = "socks5://10.10.2.1:10003";let mut http = HttpConnector::new();http.enforce_http(false);let proxy = SocksConnector {    proxy_addr: Uri::from_static(socks5_addr),    auth: None,    connector: http};let https = proxy.with_tls()?;  // wrap with TLS support if neededlet client = Client::builder().build::<_, hyper::Body>(https);// Use this client in Tonic channel:let channel = Endpoint::from_shared(server_uri)?.connect_with_connector(https).await?;
(From solution in hyperium/tonic#1206[7][11]).
Additionally, the hyper-socks2 crate’s docs provide a similar example and note it’s compatible with Hyper 1.x[11][12]. Real-world usage: the Rigetti qcs-api-client-grpc crate (Tonic 0.12.3) includes hyper-socks2 = 0.9.1 and configures the Tonic Endpoint with it[8][13], confirming compatibility.- Recommendation: Use hyper-socks2 for SOCKS5 with Tonic. It integrates cleanly with Hyper/Tonic, and supports both plain and TLS connections. We should construct our Channel with Endpoint::connect_with_connector(proxy), where proxy is a SocksConnector from hyper-socks2. This approach has known success and is maintained (as of Mar 2024)[7]. We’ll need to ensure connector.enforce_http(false) is set (to allow non-HTTP URIs like socks5:// and .onion). Also, if using TLS for gRPC, call .with_tls() on the connector as shown above[14]. No significant compatibility issues were found – just remember to handle the proxy as asynchronous and to include the hyper-socks2 dependency. (Alternative: tokio-socks could work at a lower level, but we’d have to implement the Hyper Service ourselves – since hyper-socks2 already does that, it’s the quickest path.)
Q3: Bitcoin Core Tor Implementation Details
	•	Answer: Bitcoin Core uses a dual strategy: a SOCKS5 proxy for outbound connections and Tor’s control port for inbound hidden services. Outbound: Bitcoin Core routes traffic via a SOCKS5 proxy (usually Tor’s SOCKS port), with stream isolation enabled by randomizing proxy credentials per connection. Inbound: if -listenonion is enabled, Bitcoin Core uses the Tor ADD_ONION control command to create a v3 hidden service for the p2p port. The node’s peer storage supports .onion addresses (since addr v2/BIP155) by encoding them as a separate network type, and it favors Tor circuits to prevent IP leakage. Bitcoin Core takes care to not leak the real IP when Tor is used – e.g. disabling local address discovery and UPnP when a proxy is set[15][16]. Stream isolation is achieved via unique user:pass for each connection (Tor’s IsolateSOCKSAuth ensures these use separate circuits[17]).
	•	Confidence: High. These details are drawn from Bitcoin Core’s documented options and code comments, as well as official release notes. Bitcoin Core’s approach is well-known and considered the reference.
	•	Evidence:
	•	SOCKS5 Proxy & Isolation: Bitcoin Core by default randomizes the SOCKS username/password on every connection (-proxyrandomize=1 by default), which “enables Tor stream isolation”[16]. A recent code comment explicitly notes this “generates unique SOCKS credentials per proxy connection… prevents connection correlation by forcing different Tor circuits”, relying on Tor’s IsolateSOCKSAuth[17]. In effect, each peer connection gets a separate Tor circuit, protecting privacy.
	•	Onion Service for Inbound: If -listenonion (on by default) is true, bitcoind will connect to Tor’s control port (-torcontrol) and issue an ADD_ONION command to register a hidden service on the p2p port. By Bitcoin Core v0.21, this creates a v3 onion address (it stopped using old v2)[18]. The onion service private key is stored in onion_v3_private_key in the data dir[18], so it persists across restarts. The node then advertises this .onion to peers (so others can reach it).
	•	Peer Database & .onion: Bitcoin Core’s address gossip and peer DB (peers.dat) were upgraded in v0.21.0 to support Tor v3 addresses (56-character .onions). They implemented BIP155 (ADDRv2 message) which allows up to 32-byte addresses and includes a network identifier for TORV3[19][20]. Older versions couldn’t handle v3; now it’s fully supported. The peers.dat format change is noted in release notes: it can now store Tor v3, and uses a distinct network ID so that onion addresses are serialized properly without confusion with IPv6[19]. Essentially, Bitcoin Core treats .onion as a separate network type (NET_ONION), and nodes can restrict to onion-only via -onlynet=onion.
	•	Preventing IP Leakage: When a proxy is configured, Bitcoin Core disables certain behaviors that could leak information. For example, -discover (local IP discovery via UPnP/ICMP) is turned off by default if -proxy is set[15]. It will not do DNS lookups on clearnet – any required name resolution (like seed domain names) can go through Tor’s SOCKS (Bitcoin Core can use Tor’s SOCKS5 to resolve seeds, or it has built-in onion seeds). Additionally, if Proxy is used, by default Bitcoin Core won’t listen on non-onion interfaces (unless explicitly told). In fact, running with -proxy but without -onlynet=onion will still route all traffic through Tor exits; however, best practice for pure Tor mode is also -onlynet=onion to avoid even attempting clearnet peer connections. Bitcoin Core also sets a short timeout for hostname lookups through Tor and prioritizes existing onion addresses over DNS seeds when in proxy mode. No clearnet connections are made if onlynet=onion is used – this ensures all P2P goes through Tor.
	•	Implementation Notes: In the source, the Tor control interaction is handled in torcontrol.cpp. Bitcoin Core periodically checks Tor via GETINFO net/listeners/socks to see if the Tor proxy is up[21]. It uses ADD_ONION … Flags=DiscardPK if it doesn’t need the private key back, otherwise it parses the ServiceID and saves the key. By default it auto-generates and saves a key to keep a stable onion address across restarts[18]. Stream isolation is set by constructing the Proxy object with randomize_credentials=true (in netbase.cpp), which ultimately uses a random 8-byte username each time[17]. The Tor manual confirms Tor’s default IsolateSOCKSAuth will treat each unique login as a separate circuit[22].
	•	Gotchas and Comments: Bitcoin Core devs have commented that Tor must be running for -listenonion to succeed – if Tor is down, the hidden service isn’t created (Core will log an error but continue without onion). Also, Bitcoin Core uses stream isolation by default (proxyrandomize=1) because not doing so “would link all your outbound connects to the same circuit, harming privacy” (as noted in their docs). Another detail: Bitcoin Core’s socks code supports Tor’s extended error codes for .onion connections (like telling you if an onion address was invalid or unreachable) and will log those for debugging[23][24].
	•	Recommendation: Mirror Bitcoin Core’s approach:
	•	Use a SOCKS5 proxy with randomized credentials for all outbound peer connections. This is straightforward with our networking stack (Tokio Tonic): set the proxy and generate a random user/pass for each new connection attempt. This achieves the same circuit isolation Bitcoin has[17].
	•	Implement hidden service support via Tor control port for inbound. That means adding a component to connect to Tor’s control socket (e.g. at 127.0.0.1:9051) and sending an ADD_ONION command to register our service. We should request a ED25519-V3 service (modern onion). Bitcoin Core’s -listenonion logic is a good template: after creating the service, they get back ServiceID (the onion address)[25] and possibly PrivateKey (unless using DiscardPK). We can similarly retrieve and persist the private key (so our address is stable) or let Tor manage it.
	•	Adopt BIP155 addr formats if not already – meaning ensure our peer address serialization can handle 32-byte addresses. Since we use Rust, we can use something like Multiaddr or our own encoding to store onion addresses. But as long as we treat them as opaque strings of length 56, that’s fine for initial integration. (Bitcoin’s addr message includes a network byte of 0x03 for Tor v3, followed by 32 bytes of pubkey and 2 bytes of checksum and 1 byte version, but we can avoid low-level details by not needing backward compatibility with old addr messages in our new protocol).
	•	Prevent leaks: If user enables Tor-only mode, do not initiate any clearnet connections. Also avoid any DNS lookups outside Tor. In practice, that means if Tor proxy is on, resolve peer hostnames via the proxy (socks5h:// in Rust will do remote resolve). Our peer discovery should be able to distribute .onion addresses and use them directly (no DNS needed).
	•	Use stream isolation exactly as Bitcoin does – this is critical. The implementation is as simple as generating a random string for username (and/or password) for each new outbound peer. The Tor Project strongly recommends this (and has it on by default)[22]. In summary, follow Bitcoin Core’s mature design: it has stood the test of time. This gives us confidence in privacy and compatibility with the broader network (other Bitcoin-like nodes will already know how to connect to onion peers, etc.).

Section 2: Validation Findings (High-Priority Details)
Q4: Other Blockchain Nodes with Tor Integration
Many privacy-conscious cryptocurrency projects have implemented Tor or similar. Key findings:
	•	Monero (monerod): Monero doesn’t natively spawn Tor, but it supports running as a hidden service and routing traffic through Tor. The Monero daemon has options for this: you manually configure Tor and then set Monero’s proxy and “anonymous inbound”. For example, one can add in monerod.conf:
	•	tx-proxy=tor,127.0.0.1:9050,disable_noise – to send P2P traffic through Tor (the disable_noise flag turns off Monero’s own noise protocol when using Tor)[26].
	•	anonymous-inbound=<onion_address>:18084,127.0.0.1:18084 – to listen on an onion service. Monero requires the user to create a Tor hidden service in torrc mapping 127.0.0.1:18084 (P2P port) to an onion address[27][28]. The anonymous-inbound config tells monerod “we have a hidden service at <onion>:18084 and the local service is on 127.0.0.1:18084”.
	•	Who uses it: Privacy enthusiasts run Monero nodes over Tor. Monero’s official docs provide a step-by-step Tor setup guide (similar to Bitcoin’s)[29][26]. It’s clear Monero expects Tor to be running and configured externally: Monero doesn’t call ADD_ONION itself; instead it relies on static config. Outbound Tor usage can also be achieved by simply running monerod under torsocks, though the provided tx-proxy is more precise (it only proxies P2P and not other connections).
	•	Takeaways: Monero’s approach is more manual but instructive: they separate the Tor config from the app. They also highlight using separate ports for clearnet vs onion P2P (Monero uses default P2P port 18080 for clearnet and suggests 18084 for onion)[30] – because they serve slightly different data (Monero hides node list differently over Tor). For us, this suggests considering if any network-specific logic is needed when running over Tor (likely not for Kaspa, but worth noting differences).
	•	Ethereum (Geth/Nethermind/etc.): Ethereum’s P2P is not easily Tor-friendly out of the box. Geth doesn’t have built-in Tor integration and notably uses UDP for peer discovery (which Tor cannot route). Some users have run Ethereum nodes behind Tor by disabling discovery and adding static peers or using the experimental “DNS discovery via Tor”. For example, one guide suggests running geth with --no-discover and using torsocks geth so that TCP peer connections go through Tor[31]. But this is hacky: because Tor doesn’t support UDP, the node cannot use normal peer-finding. Instead, users supply a list of onion peers or use the few Ethereum nodes that have onion addresses. There was an Ethereum Improvement Proposal to allow Tor by doing discovery via rendezvous points, but it’s not mainstream.
	•	Bottom line: No major Ethereum client has first-class Tor support at this time. People use workarounds (torsocks, static peers). This underscores how much easier it is for us (Kaspa) since we control the P2P protocol and can integrate Tor fully. (Also Ethereum’s lack is partly due to UDP discovery – we don’t rely on UDP, making Tor integration simpler for us.)
	•	Lightning Network Nodes: Lightning (both LND and Core Lightning) have excellent Tor support, often running on Raspi nodes like Umbrel.
	•	LND: Has comprehensive Tor features. It can route all Lightning P2P communications over Tor and automatically create an onion service for inbound connections. LND’s config flags include --tor.active to enable Tor, --tor.socks=127.0.0.1:9050 for the proxy, and --tor.control=127.0.0.1:9051 with --tor.password or cookie for authentication if needed[32][33]. LND even supports Tor stream isolation with a flag --tor.streamisolation (which they note “randomizes user credentials for each connection” just like Bitcoin)[34]. For inbound, one sets --tor.v3 and possibly --listen=127.0.0.1 – LND will call ADD_ONION via the control port to get an onion and then advertise it as its node address[35][36]. Users report that LND works seamlessly over Tor, and many Lightning nodes run dual-stack (clearnet + Tor) or Tor-only.
	•	Lesson: LND demonstrates that a modern async system (it’s in Go, but conceptually similar to Rust async) can manage Tor integration. It uses Tor’s control port to automate hidden service setup. It isolates streams by random auth (which we too must do). It also has an option to restrict outbound to Tor-only while disabling inbound if desired (they mention an “outbound only” mode that ensures no accidental clearnet listening)[37].
	•	Core Lightning (c-lightning/CLN): CLN can also use Tor; it provides options in lightningd like --proxy=127.0.0.1:9050 and --announce-addr=<onion_addr> for advertising an onion. CLN doesn’t itself create the onion; users either manually create one or use a plugin. A known CLN plugin (“Torify”) automates calling Tor’s control API. So CLN’s approach is more plugin-driven but quite feasible. Many CLN nodes in the wild have onion addresses.
	•	Lesson: Even if not built-in, the community built a small integration to handle the control port. This suggests if our core code doesn’t manage Tor, someone might add it externally – but since it’s a priority for us, we’ll integrate it directly.
	•	Zcash: Zcashd inherited Bitcoin’s networking and has Tor support flags. The Zcash community identified that running Zcash over Tor helps prevent network-level metadata leakage. Zcashd’s docs explicitly state: “Zcash users may choose to connect only to Tor hidden services, and also expose their own Tor hidden service”[38]. Usage is similar to Bitcoin:
	•	zcashd -proxy=127.0.0.1:9050 to send all traffic via Tor[39].
	•	Configuring a hidden service in torrc for port 8233, then using -externalip=<myonion>.onion and -bind=127.0.0.1 and -listenonion=0 to advertise the onion[40][41]. Zcashd doesn’t yet auto-create v3 (their torrc example uses a v2 onion as a stopgap)[42][43], but they plan to support v3 before v2 is deprecated[43]. They also allow -onlynet=onion similar to Bitcoin for Tor-only mode.
	•	Key insight: Zcash shows that even a fork of Bitcoin from 2016 was able to integrate Tor with minimal changes. They did hit an issue with v3 onion integration (still pending as of their docs), highlighting that one must update serialization and logic for the larger addresses (which Bitcoin solved in 0.21). For Kaspa, which didn’t previously have Tor, we should implement address serialization that can handle up to 35 bytes addresses to be future-proof.
	•	Other networks:
	•	Lightning “layer-2” networks like Lightning Loop and Electrum servers also often run behind Tor. ElectrumX (electrum server) has an option to bind on onion; Lightning Loop uses the same LND flags to operate via Tor. The patterns are consistent: use a SOCKS proxy for outbounds and Tor control for inbounds.
	•	I2P usage: Monero and some Bitcoin Cash nodes also support I2P (another anonymity network). That’s out of scope for us now, but interestingly, Monero treats I2P similarly to Tor in config (just different proxy). Bitcoin Core 22.0 added I2P support by essentially reusing the proxy mechanism (with samourai ports etc.). This suggests our design (abstracting a “proxy connector”) could later be extended to I2P with little fuss.
Relevance to our project: These cases reinforce the best practices: - Always proxy via SOCKS and isolate. Nearly every project uses Tor’s SOCKS interface for outbound. All emphasize using distinct auth for isolation (LND and Bitcoin do; Monero by default doesn’t have multiple streams concept like that, but it doesn’t do multiple circuits per se). - Use Tor control for hidden services. The sophisticated implementations (Bitcoin, LND, CLN plugins) automate it rather than requiring the user to edit torrc. We should do the same for ease of use. - Storing onion addresses: Some projects, like Grin (via OnionV3Address struct[44]) and libp2p, have custom types to represent onion addresses as raw keys. We can simply store the .onion string in our peer DB, but we might consider parsing it into bytes for validation. - Compatibility: Running a node solely over Tor is a known use-case (“bridge” nodes, hidden services for privacy). We should ensure our node can operate in Tor-only mode (no DNS seeds, rely on bootstrap via maybe a known onion seed or user-provided peers). Bitcoin and Zcash have special handling for seed nodes when in Tor-only mode (e.g., they include some onion seeds in the code or expect user to provide). For Kaspa, we may need to think about how a Tor-only node discovers peers (perhaps use a pre-seeded list of onion peers or have dual-stack bootstrap nodes).
Q5: Tor Control Protocol Deep Dive (ADD_ONION, etc.)
Understanding Tor’s control port is key for integrating hidden services:
	•	ADD_ONION: The control command to create an ephemeral onion service. Format:ADD_ONION <KeyType>:<KeyBlob> [Flags=...] Port=<virtport>,<target>
	•	KeyType can be NEW: to have Tor generate a key, or specify a key. For v3 services, you use ED25519-V3 keys. For example, ADD_ONION NEW:ED25519-V3 Port=12345,127.0.0.1:12345 would ask Tor to make a new v3 onion that redirects port 12345 to our local 12345[45].
	•	Tor responds with 250-ServiceID=<hostname> and (unless Flags=DiscardPK was set) a 250-PrivateKey=<blob>[46]. The ServiceID is the onion address (56 base32 chars). We’ll need to capture that. If we want to preserve the onion across restarts, we should save the PrivateKey and later call ADD_ONION ED25519-V3:<savedkey> ... on startup so we keep the same address. Bitcoin Core does this (it saves the key to onion_v3_private_key and reuses it)[18].
	•	Flags: DiscardPK tells Tor not to return the private key (Tor will still keep it internally for the life of that control session). Detach flag would allow the onion to persist even after our control connection closes (the service becomes “detached” from the controller)[47]. Bitcoin doesn’t use Detach (it keeps the connection open), but projects that create onion services and then disconnect might use it. We likely will keep our Tor control connection live as long as the node runs, so Detach isn’t needed unless we crash and want onion to survive (not typical).
	•	Other flags: MaxStreams can limit how many circuits use this service (not usually needed for P2P), NonAnonymous is used if Tor is in a special one-hop mode (we won’t use that – it’s for optimizing onion services on a trusted network).
	•	Permissions: To use ADD_ONION, the Tor control cookie auth (or password) must have HiddenServiceDir permissions. In torrc, if ControlPort is open, by default ADD_ONION is enabled (unless CookieAuthentication and an external filter like onion-grater is restricting it as Whonix does). We should be prepared to authenticate and handle failure if Tor’s config disallows onion creation (e.g., some Tor package might require a __OwningControllerProcess). Generally, stock Tor on desktop allows it.
	•	DEL_ONION: Command to remove an onion service. Syntax: DEL_ONION <ServiceID> (without the .onion part). This will shut down that hidden service. Only works for services created via the control port (ephemeral). If we created one and our node is shutting down, we can send DEL_ONION <id> to clean up. If we forget, Tor will automatically remove it when our control session ends (because ephemeral services are tied to the session unless Detach was used)[48]. So DEL_ONION is optional in cleanup, but it’s polite to call it on shutdown for a clean state.
	•	GETINFO net/listeners/socks: This is a query to Tor for its SOCKS listeners. It returns the address:port of Tor’s SOCKS proxy. For example, Tor might reply net/listeners/socks="127.0.0.1:9050"[21]. Bitcoin Core uses this to verify that Tor is running and the proxy is ready (and logs it). In our case, if we want to confirm Tor’s availability, we can use GETINFO on relevant fields:
	•	GETINFO status/bootstrap-phase to see Tor’s bootstrap progress (e.g. wait until Tor is at 100% done circuits).
	•	GETINFO net/listeners/socks as mentioned, to see if SOCKS port is open.
	•	GETINFO onion/address is another one – after ADD_ONION, Tor might allow querying the current onion address(s) it has created. However, since we’ll get the ServiceID in the ADD_ONION reply, we may not need additional GETINFO calls for that.
	•	Authentication (COOKIE vs PASSWORD):
	•	If Tor’s control port is enabled with CookieAuthentication (common on Linux), Tor writes a cookie file (usually /run/tor/control.authcookie). Our client can authenticate by sending AUTHENTICATE <hex-cookie> or using the SAFECOOKIE method (a challenge-response). SAFECOOKIE is recommended: our client sends AUTHCHALLENGE SAFECOOKIE <client-nonce> and Tor responds with SERVERHASH and SERVERNONCE[49][50]. We then send AUTHENTICATE <HMAC> of the cookie and nonces[51][52]. The Stem library or tor-interface crate likely handles this. In practice, many implementations simply read the cookie file and do a direct AUTHENTICATE with it (which Tor allows if the cookie file’s content is provided in hex). That’s simpler but less secure if any untrusted users on the system.
	•	If HashedControlPassword is set in torrc, Tor will accept a password via AUTHENTICATE "password". That’s straightforward (though plain in memory; safe enough over localhost).
	•	Which to use? Cookie auth is default on many Tor installations. For our integration:
	•	On Linux/macOS: likely CookieAuth is on. We can either: try a SAFECOOKIE auth (slightly more coding) or open and read the cookie file and send it (requires our process to have read permission – on many systems Tor’s cookie is chmod 600 and owned by tor user, meaning our app can’t read it unless we run as the same user or Tor is configured differently). Bitcoin Core sidesteps this by allowing a control password in Tor (the user can put torpassword in bitcoin.conf and torrc). For us, we might do similar or advise adding our user to the tor group to read the cookie. Alternatively, we run a Tor instance ourselves under our user (then cookie is readable).
	•	On Windows: Tor Expert Bundle often uses password auth (since file permissions are tricky). We might let users set a control password.
	•	Recommendation: Implement SAFECOOKIE (as tor-interface crate likely does for ArtiTorClient) for broad compatibility. If that’s complex, at least support password auth as a fallback.
	•	Async Events to monitor: Tor control port sends asynchronous events we might want to handle:
	•	STATUS_CLIENT or STATUS_GENERAL events can inform of network problems. For example, if Tor loses internet connectivity or fails to build circuits, it might emit WARN events.
	•	HS_DESC events – these are specific to onion services. According to the spec, after a successful ADD_ONION, Tor will eventually publish the service descriptor to the Tor network. Once published, Tor emits an event: 650 HS_DESC UPLOADED <HSAddress> <DescID> <HSDir> ... indicating the hidden service descriptor is uploaded to some HSDir[53]. This confirms your service is reachable by others. We could listen for HS_DESC UPLOADED to log “Onion service is now online.” If we see HS_DESC FAILED events, that might indicate an issue (though Tor will retry automatically).
	•	CIRC events – each Tor circuit has open/close events. Probably not needed for us to monitor unless debugging.
	•	We might want to catch NOTICE or WARN messages – e.g., Tor might WARN if the onion service fails to publish or if the onion address is invalid.
	•	If we use the TAKEOWNERSHIP command (when spawning Tor ourselves), we’d watch for Tor exiting. But if Tor is external, not needed.
	•	Error codes and handling: Tor control replies with three-digit codes. Notable ones for ADD_ONION:
	•	510 Unrecognized command – if Tor version is too old to support ADD_ONION (pre-Tor 0.2.7), or if control port filter blocks it.
	•	512 – used for “command refused” or misused flags (we saw example: 512 Tor is in anonymous hidden service mode when NonAnonymous flag wasn’t given but Tor required it[54]). We likely won’t hit that since we won’t use single-hop mode by default.
	•	550 range – might indicate failure to create service (perhaps if Tor’s HiddenServiceDir is unwritable, etc.).
	•	For general control commands, 250 OK means success.
	•	Socks errors (when connecting to peers): Tor’s SOCKS5 will return special error codes in the “REP” byte for onion failures. The spec defines F0–F7 as extensions[23][24]:
	•	e.g. F0 (0xF0) “Onion service descriptor not found” (means the .onion is offline or hasn’t propagated),
	•	F6 (0xF6) “Onion service invalid address” (means we gave a malformed address)[24]. If our SOCKS library surfaces these, we can log meaningful errors to the user (like “Peer onion address not found – maybe peer is down”). Otherwise, it will just appear as a connect failure.
In summary, the Tor control protocol is well-documented and we can leverage existing libraries or straightforward parsing to use it. We’ll connect via TCP to 127.0.0.1:9051 (by default), AUTHENTICATE, then send ADD_ONION ... Port=X,.... We should keep this control connection open as long as our node runs, to maintain the onion service (Tor ties it to our session). Monitoring events like HS_DESC can be a nice-to-have for status info. Clean up with DEL_ONION on shutdown (or simply close connection which implicitly clears it).
Q6: Tor SOCKS Extensions (Stream Isolation and DNS)
Tor’s SOCKS5 support includes extensions beyond the basic RFC:
	•	Stream Isolation via SOCKS5 auth: As mentioned earlier, Tor uses the SOCKS USERNAME/PASSWORD fields as isolation tokens. By default, any difference in the username or password between two connections will cause Tor to put them on different circuits[55][56]. This is controlled by the Tor IsolateSOCKSAuth option (which is on by default in Tor’s default configuration[57]). So, best practice is simply to supply a unique username (or password) for each outbound connection. For example, Bitcoin Core sets a random username of 8 bytes for each connection; it could just as well use a GUID string. Tor doesn’t care about the format of legacy credentials – any difference isolates.
	•	In fact, prior to 2024, the rule was simply “treat the username:password string as an opaque isolation tag”[56][58]. So something like user="node1234", pass="conn5678" unique per peer is fine. There’s no need for the proxy to actually authenticate (Tor’s SOCKS always reports “NO AUTH” accepted, it then just reads whatever credentials you send). In short, this is a clever repurposing of the SOCKS auth fields purely for circuit isolation. We will do the same. If using hyper-socks2, it allows setting an Auth on the SocksConnector. We can generate random bytes for each new connector (perhaps implement a custom Tower Service that wraps the connector and injects different credentials per call).
	•	New extension format: In late 2024, Tor introduced a scheme to formalize these auth fields, to distinguish between “isolation tokens” and other uses (like Arti’s RPC object IDs)[55][58]. This is proposal 351. It defines a magic 8-byte prefix <torS0X> for usernames to indicate structured data[58]. Format byte 0 means the password field is the isolation string, format 1 means username contains an object ID and password is isolation[59][60]. Example: a username <torS0X>0 and password abc means isolation param “abc”[61]. This extension is implemented in Tor 0.4.9.1-alpha and Arti 1.2.8[62].
	•	We do not need to explicitly use this format for our purposes – if we send a username that does not start with <torS0X>, Tor will treat it as a legacy isolation string (which is totally fine)[58][61]. The extension is mainly to future-proof collisions between different uses. Unless we integrate deeply with Arti’s RPC, we can ignore the format and just send random strings. The important note is: if Tor ever decided to reject weird characters, etc., but currently it doesn’t – it allows any values (even binary).
	•	We may consider using the new format for clarity: e.g. username <torS0X>0 and then put an isolation token in password. However, this is optional. Tor will accept our legacy method either way.
	•	Conclusion: We’ll generate unique credentials per connection. They can be simple (like a UUID or random hex). Tor will isolate them. This provides stream isolation, preventing the “Domino effect” where one Tor circuit carrying multiple requests could link them together[63]. By isolating, each peer’s traffic goes over a different circuit with different Tor exit/guard, greatly enhancing privacy. The Tor Project and Whonix strongly emphasize doing this[22][64] – and fortunately it’s easy for us to implement.
	•	SOCKS5 commands for DNS: Tor extends SOCKS so clients can do DNS through Tor. There are two commands:
	•	RESOLVE (0xF0): A pseudo “CONNECT” that asks Tor’s proxies to resolve a hostname to an IP. The client sends a SOCKS5 request with command byte 0xF0 and the destination address as a hostname (in SOCKS5 address field)[65]. Tor will reply with either a success and an IP in the “remote address” field, or an error. This is used by tor-resolve tool and by apps that want DNS results. We probably don’t need to use this explicitly – if we provide an .onion address to Tor’s SOCKS, we don’t want it resolved to IP (there is no real IP), Tor will handle it internally. If we provide a normal hostname (not onion) to a socks5h:// URL, our SOCKS library will automatically issue a domain-name SOCKS connect, and Tor will do any DNS needed at the exit. For peer addresses that are IPs, no resolution is needed. For peer addresses that are DNS names (if any), using the proxy means Tor will do the lookup when connecting (the socks5 CONNECT with domain name is effectively the same as doing a remote resolve + connect). So we likely won’t call RESOLVE manually. But it’s good to know: e.g. if we ever need to do a DNS lookup through Tor (for some API call or something), we could send a RESOLVE request via the SOCKS proxy.
	•	RESOLVE_PTR (0xF1): Another extension to do reverse DNS (IP to hostname)[66]. Similarly, not likely needed in our context.
	•	Our SOCKS library might not expose these commands directly. But tokio-socks actually does have a way to issue a Tor-specific command for DNS if needed. Regardless, since all our network traffic is either to IPs or .onion addresses, we can avoid manual DNS. All .onion addresses are resolved by Tor automatically (Tor recognizes the .onion TLD and intercepts it).
	•	We should ensure that when using an HTTP(S) library or something, we use socks5h:// (the h tells libs like cURL to resolve hostnames via proxy instead of locally). In our context, Tonic’s Endpoint with hyper-socks2 will treat the target URI host as an authority string – if that host is an onion, hyper-socks2 will send it as a domain name in the SOCKS request (which is what we want). Important: We must set HttpConnector.enforce_http(false) and likely also connector.set_disable_proxy(false) if using hyper’s newer APIs, so that .onion (which is not a standard URL scheme) is not rejected and is indeed passed to the proxy. The example explicitly did enforce_http(false) for this[10].
	•	Tor-specific SOCKS behaviors:
	•	Tor does not support BIND or UDP ASSOCIATE in SOCKS (since Tor doesn’t proxy UDP except through special means)[67]. We don’t need those for P2P.
	•	Tor has a protection against misconfigured clients: if a client accidentally sends an HTTP request to the SOCKS port (common mistake), Tor will detect GET or POST at the start and return a small HTML error, rather than proxying it[68]. This shouldn’t affect us but it’s good to know (if we ever saw HTML in place of expected data, it’s likely this).
	•	Optimistic Data: Tor’s SOCKS allows sending data immediately after the CONNECT request, without waiting for the success reply[69]. This shaves off one RTT for protocols where the client speaks first. Our gRPC handshake likely has the client send something immediately after TCP connect, so Tor could send it onward even as circuits build. We don’t have to do anything to leverage this – socks libraries handle it (they’ll wait for connect success by default). But if we were implementing our own, we could optionally send a few bytes early. Not critical, but interesting: it means Tor won’t mind if TLS ClientHello (for example) is sent before the SOCKS reply arrives.
	•	Extended error codes: Already covered above, Tor’s SOCKS may give us those fancy F0–F7 error codes for onion-specific failures[23]. Our SOCKS library might simply map it to a generic error. In testing, Bitcoin Core logs these when verbose (e.g., “Onion address invalid” if you typo). We could parse them if we have access to the raw reply – e.g., tokio-socks might expose the Reply::GeneralFailure with an error code. This is a low priority (just for user feedback).
	•	Username/password format: To reiterate, the format can be anything as long as it’s unique per connection. There’s no length requirement beyond SOCKS limits (255 max for each field per RFC 1929). Bitcoin uses 8 random bytes (which are then base64 when logging). LND uses something similar (likely an incrementing random). We could use e.g. 16 characters of hex. Simplicity: we can set username to a UUID and leave password blank, or vice versa. Tor will isolate on either or both fields (the rule is: if either the username or password differ, it’s a different “SOCKSAuth”). Actually, to be precise, Tor’s isolation considers the entire pair – but typically, implementations vary only the username and leave a constant password. As long as the combination is unique, it’s fine[70]. We might just fill the username and leave password empty for less overhead.
	•	The new spec from proposal 351 indicates that if using the <torS0X> format, the isolation token is effectively the “Password” field (for format 0)[59]. But we can stick to legacy usage.
	•	One edge case: If a user configures Tor’s SocksPort with IsolateDestAddr or IsolateDestPort flags (Tor has many isolation flags[71]), those could further isolate streams by target address or port. By default, those are off. But if they turned on IsolateDestAddr, then every different peer IP would use a different circuit even if the SOCKS auth was the same. That wouldn’t hurt us (we already separate by auth). Just to be aware: Tor’s isolation flags can only increase isolation, not decrease it beyond our provided auth.
Summary: We will generate a random string (e.g. base32 or hex) for each outbound connection’s SOCKS username. This triggers Tor’s per-connection isolation, which is a must for privacy[17][22]. We won’t worry about the new <torS0X> prefix unless we need compatibility with future Arti controllers, but we could adopt it trivially (it’s literally prefixing the username with <torS0X>0). For DNS, ensure any hostname (especially .onion) is resolved by Tor: use socks5h:// or equivalent so the local system doesn’t try to resolve it. Tor will handle .onion internally (it doesn’t do a DNS lookup; it recognizes the address format and routes to intro points). And if any clearnet DNS is needed, Tor will do it via exit nodes (thus not leaking to our DNS).
Q7: .onion Address Handling Best Practices
Onion addresses (v3) have a specific format and length, and we should handle them carefully:
	•	Format: A v3 onion address is a 56-character lowercase alphanumeric string, all in the [a-z2-7] alphabet (base32)[44], followed by the suffix “.onion”. For example: abcde12345...xyz.onion. The 56 chars encode:
	•	32-byte ed25519 public key,
	•	2-byte checksum,
	•	1-byte version (which is 0x03 for v3). The presence of the suffix and the version byte distinguishes it from older v2 onions (which were 16 chars).
	•	Validation: We should validate any .onion addresses we accept or store:
	•	Check length = 56 chars (excluding “.onion”)[44].
	•	Check all characters are in the base32 set (no “0”, “1”, etc. – only a-z and 2-7) – this ensures it’s a valid encoding.
	•	Optionally, verify the version byte and checksum: This means base32-decode the 56 chars to get 35 bytes. Verify byte[34] == 0x03 (version) and that the checksum (bytes[32..33]) is correct (Tor’s checksum = SHA3-256(".onion checksum" || pubkey || version)[0..1])[42]. This is how Tor itself validates addresses. This step is optional for our code – if an address fails this, Tor’s SOCKS will also reject it with error F6 (invalid address)[72]. But doing it can quickly catch typos. For instance, Zcash noted they plan to implement v3 support with such validation before Tor v2 is disabled[43].
	•	There are Rust implementations: tor-hscrypto crate has functions to encode/decode onion addresses from keys[73]. Also torut::onion module provides utilities for v3 addresses (likely generating and validating)[74]. We could use those to avoid reinventing. For example, tor-hscrypto in Arti can convert an ed25519 keypair to the onion string and vice versa (ensuring correctness)[73].
	•	Multiaddr: If we ever use libp2p’s Multiaddr, it has an Onion3Addr type which holds the 32-byte key + port, and can parse/format .onion strings[75]. We may not need multiaddr in our project, but it’s a ready parser.
	•	Storage: It’s usually fine to store onion addresses as strings in our peer DB. Bitcoin’s peers.dat (addrman) stores addresses in a compact form: for Tor v3, they store the 32-byte pubkey and set a network byte to indicate onion. In our Rust node, we can similarly store a struct like:
	•	enum PeerAddr {    Ip(SocketAddr),    OnionV3([u8; 32], u16),  // pubkey and port    // ... possibly other types}
	•	This way we separate logic for onions. But this might be overkill if we just treat everything as a string and use different dial procedures (our dialer can inspect “.onion”).
	•	A middle ground: We could parse the onion to bytes upon input and store the 32-byte key (or the full 35 bytes including checksum+ver). This would save some space and also canonicalize the address (no case issues – base32 is case-insensitive but we can store lowercase consistently). However, converting it back to a string to display or connect isn’t hard.
	•	If we expect to often need the ed25519 public key (for future crypto use, e.g., maybe verifying an onion’s identity), storing it is beneficial. But currently, it’s only used as part of the address; Tor handles verification of it.
	•	Simpler approach: store the .onion string as given, ensure it’s lowercase. That should suffice for now. We just need to be careful to not mix it with normal IP addresses in sorting or whatever (we can tag the entry as onion by checking suffix).
	•	Parsing libraries:
	•	torut::onion: as noted, likely has OnionAddressV3 type or similar which can be constructed from a string and validated.
	•	grin_wallet_util’s OnionV3Address: It stores an onion internally as a 32-byte raw key and can output the address[44]. That indicates an approach: parse base32->bytes, validate version & checksum, then keep the pubkey bytes. They might have open-sourced that parsing logic which we could reference.
	•	Best Practices:
	•	Always include the .onion suffix when displaying or in config files, to avoid confusion (some tools accept without .onion, but it’s good to be explicit).
	•	Don’t treat onion addresses as “DNS names” in the traditional sense – e.g., we should skip any normal DNS resolution. Instead, pass them directly to Tor. For example, if user enters an onion in a config, we connect via proxy, not try any other path.
	•	Normalize to lowercase. The base32 alphabet is case-insensitive, but usually lowercase is used. We should either reject mixed-case or downcase it.
	•	If we ever log or print an onion address, do not truncate it (the whole thing is needed, obviously). But also consider privacy: if logs could be seen, the onion address of our node is sensitive if it’s supposed to be hidden – it’s essentially the node’s identity. Bitcoin Core actually prints the onion address in the logs when it’s created (because it’s your node’s address to share) – that’s okay, just user should know it’s not a secret (it’s public by design, unless client auth is used).
	•	Client authentication: v3 onion services support optional client auth (stealth level). If enabled, the onion service is not reachable unless the client has a key. Bitcoin and our use case do not use this (they run public services). We likely won’t either. If we wanted, Tor control ADD_ONION supports ClientAuthV3 fields to add authorized clients[45]. Not needed for now.
	•	Conclusion for implementation:
	•	We’ll implement a small validator for .onion strings (length and charset). Use it when a user inputs an address or when reading from peer sources.
	•	Internally, for connecting, no transformation needed – just give the address (with port) to the SOCKS connector (e.g., Uri::from_static("example.onion:12345")). The rest is handled by Tor.
	•	If developing a custom dialer, we’d do something like: if domain ends with “.onion”, don’t do DNS, just pass domain as is to SOCKS.
	•	We will also ensure that in our address serialization (if we have a custom format for peers), we accommodate up to 56+5=61 char hostnames. For example, if we ever had to pack addresses into a binary format, allocate 35 bytes for onion (like Bitcoin does in ADDRv2). But since our peer exchange might be simpler (we can even exchange as strings in JSON or so), it’s fine.
Sources & examples: Bitcoin’s CNetAddr has a helper to parse onion addresses to 16-byte (for v2 they did “onioncat” IPv6 mapping). For v3, it uses addrv2: network byte 0x03 and 32-byte raw key[20]. That’s a reference if needed. Also, Rust’s libp2p Multiaddr usage (the commit shows that libp2p expects a 35-byte and specifically notes the last byte 0x03 issue[76]).
Given all that, our plan: accept onion addresses from config or DNS seeds if provided, validate them, store as lowercase strings marked as Onion type. Use a specialized connector for them (though hyper-socks2 will handle it if given a Uri with “.onion” host).

Section 3: Production & Deployment Concerns
Q8: Cross-Platform Tor Deployment
Supporting Tor on Linux, macOS, Windows (and possibly containers) requires some deployment planning:
	•	Linux: Most Linux users can simply install the tor package from their distro (apt install tor on Debian/Ubuntu, etc.). We should document this dependency. Our software can either fail gracefully if Tor isn’t present (“Tor proxy connection failed – is Tor running?”) or we could attempt to launch Tor ourselves. Bitcoin Core does not ship Tor; it expects the user to have it if they enable -proxy. We can follow that approach for now. Advanced: We could bundle the Tor daemon binary in our releases (some projects do this for convenience, e.g., the Zeus LN wallet bundles Tor on Android). But bundling raises update responsibilities (we’d need to update Tor for security fixes).
	•	Suggestion: Initially, treat Tor as an external dependency – simpler and avoids issues. Provide instructions for Linux: “install tor and ensure it’s running (as a service)”. Our node can then connect to localhost:9050/9051. This is straightforward and uses the system’s Tor, which likely stays updated via package manager.
	•	If we later package an all-in-one Docker or Snap, we might include Tor inside that container.
	•	macOS: There’s no system Tor by default. Users can install via Homebrew (brew install tor) or use Tor Browser (which includes tor daemon). Homebrew’s tor can run in background via brew services start tor. We should mention this. Alternatively, we could ship a Tor binary for macOS. Tor Project provides source; we’d have to code-sign it for macOS if distributing ourselves. That’s non-trivial, so better to rely on Homebrew or Tor Browser.
	•	We might add a check: if /Applications/Tor Browser.app exists, we could use its tor. But that’s hacky (Tor Browser’s tor might not expose control port by default).
	•	So, likely instruct Mac users to install Tor daemon via brew or MacPorts.
	•	Windows: Windows doesn’t have Tor pre-installed. The Tor Project provides the Tor Expert Bundle – a zip file containing tor.exe and needed DLLs, without the browser UI. Many Windows Bitcoin/Lightning node distributions include Tor by either prompting the user to install the Expert Bundle or bundling it. For example, Wasabi Wallet bundles Tor binaries. We have to be careful with antivirus false-positives – Tor binaries sometimes trigger warnings (because Tor is sometimes misused). But since Tor is well-known, it’s usually fine if downloaded from official sources.
	•	Options:
	•	During our installer, detect if tor is present (maybe via PATH or common install path) – unlikely, most Windows users won’t have it.
	•	Provide an option “Download and install Tor”. Perhaps our UI (if any) or CLI could on first run fetch the Expert Bundle from torproject.org and unpack it in our app directory. This is how some lightweight apps do it. The user should consent as it’s an external dependency.
	•	Bundle Tor: We could include tor.exe (and OpenSSL DLLs it needs) in our installer. We’d need to track Tor version updates and update our installer accordingly.
	•	We should also consider how to run tor on Windows: either as a background process launched by us or ask user to run it manually. LND, for instance, can launch tor (they have a flag --tor.exe to specify path, and LND will start tor and issue TAKEOWNERSHIP). If we go that route, we need to monitor the process and ensure proper shutdown.
	•	Initially, a simpler approach: instruct Windows users to download Tor Expert Bundle themselves. It’s not a friendly UX, but early adopters might manage. Eventually, providing a bundled solution (maybe with an optional Tor installation step) will vastly improve usability for non-technical users.
	•	Process management: If we rely on system Tor (Linux, possibly Mac), that’s usually run as a service (deamon) by root with a dedicated tor user. On Windows, if we bundle, we’d run tor in the user session (no service needed, as usage will be occasional).
	•	If our app spawns Tor, we should use Tor’s __OwningControllerProcess mechanism. This means when launching tor, pass --control-port 9051 --CookieAuthentication 1 --CookieAuthFile <path> --__OwningControllerProcess <PID> (Tor command-line options). The owning process option tells Tor “if this PID (our app) goes away, shut down”. And once we connect via control port, we send TAKEOWNERSHIP to tie it together[77][78]. This ensures Tor doesn’t outlive our app unexpectedly.
	•	We also might need to specify data directory for Tor if we want ephemeral (the hidden service key needs to be saved either by us or by tor). If we want Tor to save the onion private key to disk across sessions, we might actually not want tor in ephemeral mode – instead, one could configure a static HiddenServiceDir via torrc. But ephemeral services via control port can also be made permanent by storing the key ourselves.
	•	It might be easier to let Tor run continuously (as in Linux service) because then the onion stays up across our app restarts if we reuse the same key.
	•	Docker: Many users run crypto nodes in Docker containers. For Tor, there are two patterns:
	•	Tor inside the same container: The container includes a tor process alongside the node. This is simple to set up (just install tor in image and start it via supervisord or a script). It keeps everything self-contained. However, it might be less modular.
	•	Tor in a sidecar container: e.g., run tor container (some images exist) and link it to the node container’s network. The node then connects to tor:9050. This aligns with the Unix philosophy (one service per container). Docker Compose can manage this easily.
	•	Both approaches work. Projects like Umbrel often run LND and Bitcoin in one container and Tor in another.
	•	For our deployment, we should ensure that the configuration allows pointing to a Tor host (not just localhost). E.g., environment variable for TOR_PROXY could be torproxy:9050. So we must not hard-code 127.0.0.1 in container setups – allow override.
	•	If packaging in Docker, including tor has minimal overhead (~3-5 MB binary). It might simplify things for a one-container solution – user doesn’t need to run multiple containers.
	•	Minimum Tor version: We require Tor ≥ 0.3.5 for v3 onion at least (Tor 0.3.5.x was the first stable with v3 supported by default). Actually, Tor 0.2.7 had ADD_ONION (for v2), Tor 0.3.2 introduced v3 (but marked stable later). By now (2025), any Tor from official sources will be 0.4.x. We should target Tor 0.4.5 or newer ideally. If the user has an ancient Tor (unlikely unless running old OS), our control commands might fail. We can detect Tor version with PROTOCOLINFO 1 (it returns a version) and warn if too low (e.g., <0.3.5).
	•	Arti as an alternative (if it were ready) would allow bundling Tor-like functionality in Rust, avoiding external process. But as we concluded, Arti onion service isn’t ready for production. So external Tor it is.
Recommendations: - Document prerequisites clearly. For example: “To use Tor integration, you must have Tor installed. On Linux, install via apt/yum. On Windows, download Tor Expert Bundle vX.Y.Z from torproject.org. On macOS, use Homebrew or Tor Browser.” - Provide config options for Tor control address/port and auth. Perhaps allow: tor_control_addr=host:port, tor_control_password=... in a config file. (If cookie auth, we might not need a password, just the path to cookie, which on Linux is default, on Windows might not exist.) - Consider bundling in the future, especially for Windows. Possibly ship tor.exe in our release zip and on first run, spawn it. (But ensure to follow Tor license and also provide notice – Tor is BSD-3 licensed, so okay, but we should attribute.) - Ensure cross-platform path handling: e.g., on Windows, Tor’s default torrc is in C:\Users\Name\AppData\Roaming\tor\torrc. If we spawn Tor, we may provide our own torrc (e.g., to set data directory to our app’s data folder). On Linux, likely just use system tor – no need to mess with torrc. - Keep in mind firewall considerations: Tor by default connects out on port 9001, 443 etc. If a user’s firewall blocks Tor, our node won’t work. But that’s not our problem specifically – it’s Tor’s. We may just need to note it in troubleshooting.
Q9: Performance Characteristics of Routing P2P over Tor
Using Tor will impact network performance in several ways:
	•	Latency: Expect significantly higher latency for P2P messages. A Tor circuit typically adds ~50-100ms latency per relay, and there are 3 relays (entry, middle, exit for clearnet, or 3 hops plus service for onion). So round-trip latency can be ~300-600ms instead of, say, 50ms on clearnet. In practice, latency variability is high – could be 1-2 seconds if circuits are under load[79]. For blockchain nodes, this means block and transaction propagation is slower. If our node is behind Tor only, it will likely receive blocks a bit later than clearnet peers. This is an acceptable trade-off for anonymity. But it does mean that in timing-sensitive protocols, we should be aware.
	•	For Kaspa, which is DAG and has timeliness aspects, we should measure if Tor latency could cause any issues (like would it be slower to hear block messages and thus at a disadvantage in propagating?). Since many nodes won’t be Tor, and Tor nodes are presumably not miners, this might be okay.
	•	We may consider increasing certain timeouts: e.g., peer handshake timeouts. If currently we wait 5 seconds for a version handshake, Tor might need slightly more. Bitcoin Core, for instance, has appropriate conservative timeouts that work over Tor – they allow up to 60 seconds for some operations. We should audit our networking timeouts and maybe extend them when tor_enabled.
	•	Throughput/Bandwidth: Tor relays have bandwidth limits. While the Tor network can handle many MB/s, any single circuit might be limited by the slowest relay in the path (some relays allow only a couple MB/s). For a blockchain node, the biggest bandwidth events are syncing the chain and handling large blocks. For example, downloading the entire chain over Tor could be quite slow. A 1GB blockchain might take many hours over Tor depending on speeds (500 KB/s to 1 MB/s is realistic for sustained Tor downloads on a decent circuit). It’s not uncommon to see Tor circuits give 100-300 KB/s if the relays are under heavy load.
	•	Mitigation: There’s not much we can do except possibly open multiple connections and parallelize sync (which is tricky and could actually stress Tor more). Bitcoin Core doesn’t do anything special here – Tor nodes sync slowly. It’s a known trade-off: anonymity vs speed.
	•	We should warn users that initial sync will be slower on Tor. Perhaps recommend they sync over clearnet first, then enable Tor (if their threat model allows that).
	•	Circuit build time: The first time our node connects to a new peer via Tor, Tor has to build a circuit (if none exists for that credential). Circuit building takes a bit of time (a second or two typically to get to 100% bootstrapped state, and a few hundred ms to extend to each hop). The CONNECT will not succeed until the circuit is established to the target (or to an exit if target is clearnet). This adds a one-time delay per connection. If we open many connections simultaneously, Tor will build circuits in parallel. But there might be some limitation (Tor often doesn’t build too many at once to avoid overloading the network).
	•	So, establishing 8 outgoing peer connections might take, say, 5-10 seconds total via Tor. That’s fine. We may just need to be patient in our code (don’t mark peers as failed too quickly).
	•	For onion services (incoming): when another Tor node connects to our onion, their Tor builds circuits to our HS. That introduces delay in peer handshake as well. It’s symmetric though – both sides via Tor means possibly multi-second handshake times.
	•	CPU/Memory overhead:
	•	Running Tor (the daemon) will consume some CPU for encryption and memory for circuits. On modern hardware, Tor’s CPU usage is usually modest for a handful of circuits. Each Tor circuit encryption is not too heavy (AES and curve25519 mostly, which are fast with CPU AES-NI). Even an underpowered Raspberry Pi can handle a Tor node plus Bitcoin.
	•	Memory: Tor might use on the order of ~100 MB of RAM when actively transferring data at high rates (it caches some, and has to store circuit states). Arti is reported to use more memory currently (maybe 100-200MB)[80]. For our environment, adding ~100MB overhead is generally fine given modern nodes have gigs of RAM. But it’s worth noting so we’re not surprised by a jump in usage with Tor on.
	•	If bundling Tor in our process (via Arti) we’d have to manage memory within the same heap; but with external Tor, it’s separate.
	•	Connection management:
	•	Tor by default limits total circuits and connections. If our node tries to connect to, say, 100 peers over Tor, it might stress Tor. Bitcoin by default doesn’t attempt more than 10 outbound and a few inbound for onion. We should also be mindful: it’s probably not wise to run a high-connection count node purely over Tor (not a technical limitation so much as it might overwhelm the Tor instance or cause lots of overhead).
	•	Perhaps we should limit the number of Tor connections a bit. Bitcoin Core has a compile-time default of 8 outbound; it allows inbound up to 117 including onion. In practice, Tor hidden services can handle many inbound, but each consumes a circuit at the client side and introduction/rendezvous at our side.
	•	There is also a Tor config MaxClientCircuitsPending that limits how many circuit extends can happen in parallel – large scale might trigger that.
	•	Stream isolation impact: With every connection on a separate circuit, none of our peer traffic benefits from Tor’s circuit reuse. This is good for privacy, but it means if we have 8 peers, we have 8 circuits – so 8x the overhead (each circuit’s relays carrying traffic). If one peer is very high traffic (e.g., during initial sync, one peer might send blocks continuously), that one circuit will be taxed but at least others won’t interfere. If we had not isolated, multiple peer traffic could share a circuit, possibly saturating it. So isolation might actually improve throughput distribution across peers, at the cost of a bit more CPU and maybe less “Tor-friendliness” (we are consuming more circuits). The Tor network by design can handle multiple circuits from a client.
	•	Parallel downloads: If our node supports parallel block fetching (like some do, fetching different parts from different peers), Tor might be a bottleneck if all are limited by the same guard node bandwidth. Because even with separate circuits, typically they share the same Tor guard relay (the first hop, which is unique per Tor client for a long time). This means all our traffic ultimately goes through one guard’s capacity. So running 8 parallel downloads doesn’t get 8x bandwidth – it gets limited by that guard. This is an anonymity feature (Tor sticks to one guard to prevent exposing you to many malicious entry nodes). So in effect, our total throughput is capped by one Tor guard’s speed. This is important: adding more peers might not increase aggregate throughput linearly in Tor, because they converge at the guard.
	•	However, if we run a bridge or a custom torrc with multiple guards, that’s advanced usage. By default assume one guard.
	•	Implications:
	•	It might take longer to propagate and receive information, but as a full node that’s acceptable as long as it eventually syncs and relays.
	•	For mining or ultra-low-latency scenarios, Tor is unsuitable. We should note that our Tor mode is for privacy, not performance.
	•	If Kaspa’s protocol has any time-based scoring (e.g. dropping slow peers), we should adjust thresholds when in Tor-only mode to avoid unnecessarily dropping peers that are slow due to Tor. Possibly treat Tor peers more leniently.
	•	Arti vs Tor daemon performance:
	•	The Tor Project indicated Arti’s performance and stability haven’t yet matched C Tor[81]. In particular, Arti has not been optimized for relay or heavy client load fully. Some benchmarks (community) showed Arti uses more CPU for the same throughput. So using the C Tor daemon is likely more efficient at this time.
	•	Memory: Arti memory usage was a bit higher in early versions. By 1.6, it’s better but still new. The C Tor is written in C and tuned over years, often using less RAM for similar tasks.
	•	So from a performance perspective, sticking to the Tor daemon is also beneficial, beyond the functional reasons.
	•	Privacy-vs-Performance configuration: Tor has some settings that can trade a bit of privacy for speed:
	•	One-hop onion service (HiddenServiceSingleHopMode): This is an option where your onion service runs with only one relay between you and the client (no anonymity for service, but client stays anonymous). It’s used for onion services that just want censorship-resistance but don’t need anonymity for the server. If we were purely concerned with performance for inbound (and didn’t mind if someone could theoretically discover our IP via guard analysis), we could use this. But it’s not recommended for a privacy-focused node. By default we will not use NonAnonymous mode. If someone wanted a “high-performance onion”, they might set that in torrc manually; our control ADD_ONION would need Flags=NonAnonymous to allow it[54]. We will avoid this unless a special use-case arises.
	•	Disabling stream isolation: If a user really wanted to minimize circuits, they could disable proxyrandomize. But that is strongly not advised (Bitcoin Core leaves it on by default, and nearly everyone agrees to keep it). The latency saved by circuit reuse is minor compared to the loss in privacy. So we will always isolate.
In summary, running our Rust node over Tor will be slower – that’s expected. We should ensure our code accounts for this by adjusting timeouts and informing the user. It’s a fair trade for the added privacy. Also, since we are not a low-latency application like web browsing, a few-second delays are tolerable. Throughput might be the biggest pain for initial sync. After sync, daily bandwidth (block and tx relay) is small enough that Tor can easily handle it.
Q10: Security & Privacy Considerations
Using Tor greatly enhances privacy, but there are still considerations and potential pitfalls:
	•	Tor provides anonymity, not magic invincibility: It hides the node’s IP address effectively and thwarts many passive surveillance attacks (no one on the P2P network can trivially determine your IP if you only use Tor). However, Tor is vulnerable to certain attacks:
	•	Correlation attacks: If an adversary can observe both ends of your communication (the traffic entering Tor at your end and traffic leaving Tor to a peer), they could correlate timing and volume to de-anonymize. This is hard at scale, but nation-state attackers or global observers pose a threat. Using Tor reduces this risk compared to clearnet (where an observer directly sees your IP in the P2P messages), but if the adversary runs enough Tor relays, they might statistically deanonymize some users. The Guard relay design mitigates this by sticking with a few guards so a user isn’t exposed to many malicious entry nodes[82][83].
	•	Sybil attacks on P2P with Tor: An attacker could still flood the network with Sybil nodes that all connect to you (even over Tor) and try to infer you are the same hidden node by behavior, or attempt to degrade your connections. Tor doesn’t prevent Sybil within the P2P context – we still need other Sybil resistance at the protocol level.
	•	Eclipse attacks: If an attacker manages to fill all your peer slots (Sybil) and isolates you, Tor doesn’t inherently stop that. Bitcoin Core had concerns in the past that Tor users might actually be more vulnerable to eclipse, because Tor connections were slower and sometimes ended up all connecting to attacker-controlled onion seeds[84][85]. Mitigation: ensure we have a diverse peer selection and maybe use both onion and exit peers. Bitcoin addresses this by having some fallback onion peers and logic to avoid all peers being from the same /16 etc. In Tor, those concepts differ, but perhaps ensure not all connections go through the same exit (though with one guard, if attacker controls that guard, it’s game over anyway).
	•	Privacy leaks in our implementation: We must ensure that when “Tor privacy mode” is enabled, absolutely no traffic goes out via clearnet:
	•	No DNS queries – use socks5h or Tor’s resolver for everything (even for bootstrap DNS seeds or known domain).
	•	No HTTP calls that might leak (if our node has any telemetry or NTP time sync, proxy them too or disable them). For instance, if our node time syncs from an NTP server – doing that over Tor or not at all. (Bitcoin Core actually doesn’t do external NTP by default due to privacy; it relies on peer timestamps).
	•	We might consider disabling the auto-updater (if any) or having it fetch updates via Tor (to not leak that you’re using this node software).
	•	If our node has logging, be mindful not to log the real local IP when Tor is on (though typically it wouldn’t). Also, don’t log the control port password or cookie path in detail.
	•	Ensure that if Tor fails, and user has “Tor-only” mode, we don’t silently fall back to clearnet. Better to shut down or isolate. Bitcoin has a -onion option separate from -proxy to ensure if Tor isn’t available, it doesn’t use clearnet by accident.
	•	Control Port Security:
	•	If an attacker could access our Tor control connection, they could deanonymize us by retrieving our onion private key or creating their own services. So we must keep that interface secure. Since we connect to 127.0.0.1, only local processes can attack it. We should ensure we authenticate properly (with cookie or password) so no rogue local process can hijack our session.
	•	On multi-user systems, reading Tor’s cookie file is a privilege (usually only tor user or group can). If our node runs as a normal user and Tor is a system service, by default we cannot read the cookie file. One approach is to add our user to the tor group (if distro has that) so it can read /run/tor/control.authcookie. This should be documented if needed. Alternatively, user can configure a control password in torrc for us.
	•	The tor-interface crate’s LegacyTorClient likely can take a hashed control password to authenticate. We could integrate that route.
	•	Onion Service Operational Security:
	•	Running a hidden service (our node) means our traffic is inbound through Tor, which is good. But if our node is not pure Tor (say it also makes clearnet connections or DNS queries), then linking can happen. For best privacy, run it in Tor-only mode. If we allow hybrid (some clearnet, some Tor), there’s a risk: an attacker could observe timing of when a transaction announcement comes from this onion vs when the same node relays it on clearnet, etc. This could correlate the onion and clearnet identity as the same node. Bitcoin Core allows hybrid (they can have some clearnet peers and some Tor), but a very privacy-conscious user would do -onlynet=onion. We should offer a similar setting (perhaps default to Tor-only if Tor is enabled, or at least document the trade-off).
	•	Clock / timing: Tor can randomize clock skew a bit but generally, if our system clock is off and we include timestamps in messages, could that leak something? Probably not much, since P2P timestamps are not high precision and often user’s IP is a much bigger leak. But still, ensure we use network time adjustments similarly as Bitcoin (which in Tor-only mode uses peers’ time as well).
	•	Attack: Guard discovery for onion service: Hidden services have long-lived guard relays. Attackers might try to force a hidden service to rotate guards by DoSing it, which can eventually expose it to a malicious guard that correlates traffic to the service’s IP. This is a complex attack, partially mitigated by Tor’s vanguards (guard rotation defenses) which Arti also implemented[86]. For a node operator concerned about this, it’s more on Tor’s side to handle (which they do via Vanguards and not exposing guard info).
	•	We just note: if someone can run a malicious guard that our hidden service chooses, they can possibly do traffic analysis to guess the type of service (but linking it to an IP behind NAT still not trivial).
	•	Exit Traffic Visibility: If we connect to clearnet peers via Tor (not onion peers), those connections exit from Tor exit nodes. That means:
	•	The exit node sees unencrypted Bitcoin/Kaspa P2P traffic to some IP (our peer). However, our P2P is encrypted (if using TLS or Noise). If it’s plaintext (some coins are plaintext), the exit can read the data. Kaspa’s gRPC is over TLS I believe, so the exit can’t read content, but can see patterns (e.g. amount of data). The exit also sees the destination IP/port (so knows we are contacting a crypto node at X). This could be logged or manipulated (exits could throttle or inject packets, though if TLS, injection would break handshake).
	•	This is a consideration: for maximum privacy, it’s better to connect to other .onion nodes when possible, avoiding exits entirely (thus no third party sees traffic). Bitcoin tries to use .onion for known onion peers (it has a bunch of seed .onions and will prefer those if running Tor). If none are known, it will use exits to reach clearnet peers.
	•	For Kaspa, initially there won’t be onion peers until people run them. We might rely on exit nodes. We should ensure our protocol is encrypted or at least not trivially deanonymizing in its handshake (like, if plaintext handshake includes our node identity, an exit could note it – but since we’re hidden, maybe not).
	•	Over time, we could encourage an “onion peer ecosystem” and perhaps have some bootstrap onion addresses.
	•	If exit traffic is a concern (some Tor users don’t trust exits), they can run in onlynet=onion mode which means if not enough onion peers, you run isolated (or use a bridge to an onion peer if any). But initially to get peers, might require exit.
	•	Use of “Privacy Mode”: We could implement a “run over Tor exclusively” flag (like --tor-only). This would:
	•	Not attempt clearnet, and perhaps even refuse to run if Tor is unreachable (so you don’t accidentally run without it).
	•	Avoid DNS seeds that are clearnet. Instead, maybe rely on built-in peers or user-provided. We might publish an .onion seed for Kaspa (one or two community nodes).
	•	Not listen on clearnet interfaces (listen only on localhost and onion).
	•	Possibly disable RPC or wallet features that might leak (depending on scope; Bitcoin disables listening on clearnet if onlynet onion).
	•	Operational Security:
	•	If one is very concerned, they’d run the node in a isolated environment (like Whonix Workstation) where all traffic is forced through Tor. That way even if our app tried clearnet, it couldn’t. This belt-and-suspenders approach is used by some. We can’t enforce that, but our design should align so it works in such setups (e.g. our app not requiring root, able to use Tor’s defaults).
	•	We should note: “Do not use Tor if you rely on maximum performance or if you are the only Tor node in the network (that could be fingerprintable).” But in practice, many Bitcoin nodes run via Tor, so it’s not uncommon.
	•	Cookie file permissions:
	•	If we instruct adding our user to tor group to read the cookie, that’s a slight privilege expansion (if our app is compromised, it could control Tor via cookie – though it already could via the control connection it has). It’s probably fine. Alternatively, one can set Tor’s CookieAuthFileGroupReadable yes in torrc to allow group read.
	•	If using a control password, ensure it’s stored hashed in torrc (Tor doesn’t accept plain text in torrc, only a hash). We would then ask user to put the password in our config (plaintext). That’s okay if file is not world-readable.
	•	We must never log the control password or cookie.
	•	Also ideally, if we spawn Tor, use a temporary torrc that enables only what we need and perhaps sets DisableNetwork=0 properly after bootstrap. (Tor’s control can also toggle DisableNetwork to delay network until configured).
	•	User Privacy Expectations: We should clearly state what Tor integration does and does not do:
	•	It hides your IP from the P2P network. It does not inherently encrypt traffic content beyond what the P2P protocol does. (Though if using TLS P2P, content is encrypted).
	•	Peers will see you as an onion address (or an exit’s IP if you connect to clearnet peers). Your identity is obscured.
	•	Running a node over Tor does not anonymize wallet transactions on-chain or other layers – it purely protects network-level identity. (This is relevant if our node has a built-in miner or wallet – they should still use proper on-chain privacy techniques, but at least network connect won’t reveal their IP).
	•	Censorship Resistance:
	•	Tor integration not only provides privacy, but also helps users in restrictive networks to reach the P2P network (bypassing IP blocks). If Kaspa gets blocked in some country, a Tor hidden service node can still participate. So it’s a resilience feature. Running a hidden service means your node can accept inbound connections even if behind NAT or firewall, via Tor.
	•	We might consider supporting Tor bridges or pluggable transports for users in networks where Tor is blocked (China, etc.), but that’s future scope. At least, allow configuration of Tor’s Socks5 proxy to a bridge or local pluggable transport if the user sets it up.
Final security note: We should leverage the robust security of Tor but remain vigilant in our implementation to not introduce side-channels. For example, don’t print our onion address to an unsecured UI in a multi-user system. Don’t allow the control port to be accessible remotely. Possibly allow our RPC to be served as an onion as well (some advanced uses might want wallet RPC via onion – outside our current scope, but something to note for future).
Overall, with Tor, our node’s biggest remaining attack surface for deanonymization is if an adversary runs many Tor relays and many Sybil peers – a global adversary scenario. That’s a much higher bar than before (just connecting and logging IPs). So this integration meaningfully improves privacy when done right, as long as we heed these best practices.

Section 4: Updated Recommendations and Decisions
Bringing it all together, here’s our proposed implementation plan and risk assessment:
Architecture Decision – Arti vs C Tor: Use the C Tor daemon (External Tor) for full Tor support. Arti, while improving, is not yet production-ready for hosting onion services[1]. Relying on Arti now would risk security (missing DoS protections[87]) and stability. The C Tor has decades of hardening and will give us immediate compatibility and reliability. Therefore: - Outbound Tor (client): Use a SOCKS5 connector to Tor’s SOCKS port (hosted by the Tor daemon). - Inbound Tor (server): Use Tor control port commands to create an onion service via the Tor daemon. - We will not integrate Arti’s tor-hsservice at this stage. Perhaps keep an eye on Arti’s progress (Tor Project might declare it secure for onion services in the future), but for now, go with the proven solution. - Exception: In environments where running an external process is impossible (some embedded systems), we might revisit Arti for outbound-only usage. But even then, Arti’s client is stable, so that’s possible for outbound. The bigger issue is onion hosting, which we require. - Using the Tor daemon also benefits from Tor’s ongoing network (we piggyback on thousands of relays) and its automatic updates (if system Tor updates, our node benefits without code changes).
Library Choices for SOCKS & Control: - SOCKS5 Proxy: Adopt hyper-socks2 (or underlying tokio-socks if needed) to route gRPC connections. As validated, hyper-socks2 works well with Tonic/Hyper[7]. It’s actively used in other projects and supports TLS. We should test it with .onion addresses specifically – based on docs, it should handle them (it sends the host as a string to the proxy)[11]. If any issues, tokio-socks is an alternative where we can manually do Socks5Stream::connect to target and then hand the stream to Tonic (perhaps via transport::Channel::builder().connect_with_connector_stream() providing an AsyncRead/Write). But likely not needed since hyper-socks2 abstracts it nicely. - Another small crate socks5-proxy exists but it’s less popular; hyper-socks2 seems fine and simple. - We should also enable the tls feature of hyper-socks2 (it uses hyper-tls by default) to ensure if our gRPC is over TLS, it wraps correctly. (From the docs, with_tls() returns a connector using either rustls or native-tls behind scenes[14].) - Compatibility: hyper-socks2 0.9.1 works with Hyper 1.0.x which we have. If we upgrade Hyper in future, check for hyper-socks2 updates (there was mention of hyper-util’s client-proxy, which might supersede hyper-socks2 eventually[88]). - Tor Control API: We have a few options in Rust: - Use tor-interface crate. This crate (v0.6.0 as found) provides an abstraction LegacyTorClient and ArtiTorClient[89]. It likely handles connecting to control port, authentication, and issuing commands like ADD_ONION. If it’s well-maintained, this could speed us up. We should verify it’s production-ready. Since it’s v0.6.0 (2025), it suggests active development. Possibly used by projects like I2P/Tor controllers or the Invictus project. We should try it out in a prototype. If it works, great – it saves writing our own control protocol handling. - Use Stem (Python) as reference or implement ourselves: The control protocol is simple text, and we could implement minimal needed: write authenticate, write add_onion, parse replies. That’s not too hard but error handling and async might be fiddly. However, given we found tor-interface, leaning on it is fine. - We must ensure whichever we choose allows ephemeral onion creation. tor-interface likely does (since it mentions onion services). It may even support setting NonAnonymous or client auth if needed. - Recommendation: Try tor-interface for LegacyTor. If it doesn’t meet expectations (e.g., lacks some feature or has bug), fall back to a custom lightweight implementation using perhaps async-net or tokio to talk to the socket. The control protocol is line-oriented, which is easy to handle with tokio’s AsyncBufRead. - Onion address handling: No specialized heavy crate needed, but we could use data_encoding (for base32) and maybe ed25519-dalek if we ever verify keys. But not necessary if we trust Tor to handle addresses properly. Possibly use tor-hscrypto crate’s function to validate onion addresses for extra safety[73]. That crate is from Arti, might pull in more dependencies than needed. Simpler: write a 56-char check and base32 decode, one-time small code. - We did find Onion3Addr in multiaddr. Instead of adding libp2p as a dependency just for that, probably overkill. - We might just implement a small is_valid_onion_address(&str) -> bool for now.
Implementation Approach Summary:
	•	Tor Setup: By default, try to connect to Tor at 127.0.0.1:9050/9051. Provide config options to override addresses and authentication. If Tor isn’t running or connection fails, and user requested Tor-only, then fail with error to avoid accidental clearnet. (If Tor is optional, then we continue without Tor, but likely we have an explicit flag enabling Tor mode.)
	•	Outbound connections: Use a global (or per-Endpoint) SOCKS connector. We might create a single HyperClient with the proxy and use it for all gRPC P2P connections. Or we integrate at Tonic Endpoint level as needed. We’ll set up stream isolation by giving each new channel a distinct auth – possibly by constructing a new SocksConnector per connection with different credentials (since hyper-socks2’s SocksConnector has an auth field we can vary).
	•	Alternatively, since each Kaspa peer is a separate gRPC Channel, we can indeed give each channel its own connector instance with unique username. This is straightforward: when dialing a peer, generate random string, build SocksConnector{proxy_addr, auth: Some(Auth{user,pass}), base}, then Channel::builder(peer_uri).connect_with_connector(connector).
	•	Inbound (listening): We continue to listen on the normal TCP for clearnet if allowed, and set up an onion service. Actually, if Tor mode is enabled, we might either:
	•	Listen on 0.0.0.0:port as usual (so if user has port forwarded and someone connects via IP, they still can) – but this leaks IP so probably not for Tor-only mode. For Tor-only, we’ll listen only on 127.0.0.1 (so no clearnet inbound).
	•	Regardless, Tor onion service will point to our local listen port (likely 127.0.0.1:port to avoid intercept). The control port call ADD_ONION with target 127.0.0.1:port.
	•	Once Tor returns the ServiceID, we print it to the user (“Your node is reachable at xyz.onion:port”). We also might want to add it to our peer advertisement (if our protocol shares node addresses, we should include our onion).
	•	We keep the control connection open. Possibly handle HS_DESC events just to log “Onion service published” (optional).
	•	On shutdown, either call DEL_ONION or simply close connection (Tor will remove the service).
	•	Peer Database: Allow storing onion addresses and reconnecting to them. We should flag onion peers distinctly (so that if a user is in Tor-only mode, they choose onion peers from peer DB first). Also, if we get an address advertisement that’s .onion, store it and try it if Tor available.
	•	If running dual mode (clearnet+Tor), we may have both types in DB. We might prefer onion if both available for the same node, depending on user preference.
	•	Testing:
	•	Test outbound by connecting to a known bitcoin hidden service (just as a integration test possibly) or a dummy echo hidden service, to ensure our socks and isolation logic works.
	•	Test inbound by using Tor Browser or telnet via torsocks to connect to our onion address.
	•	Test failure cases: Tor not running (should we timeout or try again?), wrong password, etc.
	•	Ensure that if Tor goes down while node is running, our peer connections will drop (since proxy fails). Possibly handle that by marking all peers as offline until Tor returns. But that scenario is similar to internet drop in clearnet.
Risk Assessment:
	•	Blockers Identified:
	•	If hyper-socks2 had an unknown bug with .onion host parsing – but it likely doesn’t, given its usage and hyper’s flexibility. If it does, fallback is implementing a custom connector.
	•	If tor-interface crate is unmaintained or fails on some edge of ADD_ONION (we need to confirm it supports ED25519-V3; perhaps it does). If not, we might write our own or use Stem in a subprocess (not ideal). Writing our own control port handler is feasible though.
	•	Tor not running or misconfigured is a deployment risk – but that’s on the user. We should handle errors gracefully and give guidance. (E.g., if tor_control config is wrong password, log and retry or exit.)
	•	Integration complexity: making sure our P2P logic can incorporate the asynchronous nature of Tor connect (which might take longer). We might have to bump some timeouts as said.
	•	Security misstep: forgetting to isolate streams or leaking an IP somewhere. We’ve enumerated those and will remain cautious. Perhaps run a test node in Whonix to confirm no clearnet leaks (Whonix’s onion-grater would complain if our control commands are not allowed, we might have to configure that).
	•	Alternatives considered: None of the research suggests a fundamentally different approach – all projects do it this way. I2P integration is analogous but not requested. We focus on Tor.
	•	Go/No-Go: This research gives us high confidence to proceed with implementation. No show-stoppers were found:
	•	Arti’s current limitations confirm our initial plan to use C Tor – good call.
	•	Tonic + SOCKS works – we even have code examples to guide us[7].
	•	Bitcoin Core’s blueprint covers all the tricky parts – we just need to replicate in Rust.
	•	Thus, Go for implementation. The unknowns (like the exact crate usage for control) are manageable with some prototyping, but nothing appears insurmountable. Security wise, as long as we implement stream isolation and Tor-only mode properly, the benefits outweigh the risks.
We'll move forward with coding this, keeping the above considerations in mind. The outcome will be a Rust node that can operate over Tor with strong privacy, much like Bitcoin Core does.

Section 5: Gaps & Open Questions
Despite our comprehensive research, a few areas remain for further investigation or testing:
	•	Gaps Requiring Prototyping:
	•	tor-interface Crate Verification: We should do a quick prototype using tor-interface to create an onion service. Does it successfully produce a v3 onion and maintain it? Are there any bugs (for example, earlier versions might have only supported RSA1024/v2)? The crate docs were not fully in our research results aside from its API reference. We’ll have to try it in code. If it falls short, be ready to manually implement control port logic.
	•	Hyper-SOCKS5 with Tonic: While all evidence says it works, we should create a test Tonic client using hyper-socks2 to connect through Tor to a known test service (maybe a public gRPC echo service via Tor if available, or just verify the TCP connection flows through tor by watching Tor logs). This will flush out any configuration issues (e.g., ensuring enforce_http(false) etc.). Also, test that our random auth per connection is indeed being applied (maybe by enabling Tor’s circuit logging to see distinct circuits).
	•	Peer connection timeout tuning: We might need to measure handshake times with Tor and adjust. Some trial and error on the dev network can find the sweet spot (like allow 30 seconds for initial handshake on Tor peers).
	•	Integ test in a simulated Tor environment: Possibly use Docker: one container running tor, our node connecting to it, and maybe connect to a local onion service. If time permits, set up Chutney (Tor’s private network simulator) to test multiple tor nodes in a sandbox.
	•	Open Questions Not Fully Answered by Research:
	•	Monero’s P2P over Tor specifics: We saw how Monero sets it up but not internal details of how well it works. For example, Monero has a aggressive block propagation like Kaspa (since Kaspa is high-rate), can Tor handle that? Monero’s block rate is slower, so maybe not directly comparable. We might need to test Kaspa’s block flood over Tor to ensure Tor isn’t a bottleneck that causes timeouts or missed messages in our protocol. If it is, we might adapt the protocol parameters when Tor mode (like allow more slack).
	•	Tor control in multi-threaded Rust context: If our node is multi-threaded (Tokio runtime with many tasks), how will we handle the single control port connection? Probably with an event loop task dedicated to Tor control (reading events, etc.). We might use channels to send commands to it and await responses. This design we’ll have to craft; no off-the-shelf solution for integrating that into our program’s async structure was identified (though tor-interface might abstract some of it).
	•	Number of inbound onion connections Tor can handle: Not directly answered, but presumably dozens are fine. If our node becomes popular via Tor, Tor could become the bottleneck in handling many introduction circuits. Not urgent, but something to monitor once deployed. If we needed to scale, running multiple onions (with multiple Tor instances) could be a solution, but that complicates identity.
	•	Behavior if Tor crashes mid-run: Our node would suddenly find its proxy dead. We should detect and perhaps pause networking until Tor restarts. Bitcoin Core periodically checks tor via -torcontrol thread and logs if lost. We might implement a callback on control port disconnection to shut down onion service and maybe try to reconnect. This scenario is complex to test (simulate Tor crash). Possibly out-of-scope for initial release (we can document “if Tor stops, restart the node or Tor”).
	•	Future: support for connecting to peer’s .onion with client auth: Not needed now, but if someone runs a private hidden service peer (requiring auth), Tor’s SOCKS supports providing credentials (called OnionAuth in Tor). We haven’t looked at that as it’s niche. Not doing now, but leaving it for future if enterprise users want that.
	•	Need Expert Consultation?:
	•	It might be worth running our plans by a Tor network expert or someone from the Tor Project, especially regarding heavy P2P traffic patterns. Perhaps ask “Is there any concern running a high-throughput blockchain P2P over Tor for hours on end?” Usually fine, but getting confirmation would be nice. The Tor Project might also give guidance on tuning (e.g., maybe set Conflux or PoW defense off if not needed – those are onion service DoS defenses that could throttle traffic).
	•	Also, an expert could advise on corner cases like Tor control error handling. However, given our familiarity with Bitcoin’s approach, we’re likely okay without direct Tor dev input.
	•	Additional Testing in Real Network: Once implemented, we must do live tests:
	•	Set up two nodes over Tor, see if they can sync and stay in consensus with clearnet nodes.
	•	Perhaps invite some community to run Tor nodes and see if they can propagate transactions well.
	•	Monitor if Tor circuits last long enough (Tor rotates circuits for client connections every 10 minutes by default if they’re idle; but long-lived streams are left open indefinitely as long as traffic flows. Should be fine; Bitcoin stays on one circuit per peer potentially for days).
	•	Continuous Integration (CI): Running Tor in CI (like GitHub Actions) to test integration might be tricky (some CI block outbound or Tor). But we can consider adding an integration test with a local Tor instance. It might be doable using apt-get tor in a Linux runner. So we can simulate at least establishing a connection to a test onion in CI. This would catch regressions in Tor connectivity going forward.
In summary, the research has answered the main unknowns and validated that our approach is correct. The remaining items are mostly engineering tasks (implementing and testing). We should be vigilant during implementation to incorporate what we’ve learned (especially stream isolation and not falling back to clearnet). The confidence is high that we can proceed to coding with minimal unknown unknowns left.

[1] [3] [80] [81] Capability and Limitations | Arti
https://tpo.pages.torproject.net/core/arti/guides/capability-limitations/
[2] [87] tor_hsservice - Rust
https://docs.rs/tor-hsservice/latest/tor_hsservice/
[4] [5] [86] Implementations - The Onion Services Ecosystem
https://onionservices.torproject.org/dev/implementations/
[6] [7] [10] http or socks5 proxies support · hyperium tonic · Discussion #1206 · GitHub
https://github.com/hyperium/tonic/discussions/1206
[8] [9] [13] refresh.rs - source
https://docs.rs/qcs-api-client-grpc/latest/src/qcs_api_client_grpc/tonic/refresh.rs.html
[11] [12] [14] hyper_socks2 - Rust
https://docs.rs/hyper-socks2/latest/hyper_socks2/
[15] [16] Bitcoinwiki
http://bitcoinwiki.org/wiki/running-bitcoin
[17] [21] torcontrol: Add comment explaining Proxy credential randomization for Tor privacy
https://mirror.b10c.me/bitcoin-bitcoin/31973/
[18] [19] [20] Bitcoin Core :: Bitcoin Core 0.21.0
https://bitcoincore.org/en/releases/0.21.0/
[22] [71] GitHub - ben-grande/qubes-bitcoin: Qubes-Whonix with Bitcoin setup.
https://github.com/ben-grande/qubes-bitcoin
[23] [24] [65] [66] [67] [68] [69] [72] Tor's extensions to the SOCKS protocol - Tor Specifications
https://spec.torproject.org/socks-extensions.html
[25] [45] [46] [47] [48] [49] [50] [51] [52] [54] [77] [78] Commands - Tor Specifications
https://spec.torproject.org/control-spec/commands.html
[26] [27] [28] [29] [30] Tor and I2P - Monero Docs
https://docs.getmonero.org/running-node/monerod-tori2p/
[31] How tun run an Ethereum node over Tor (and Why) - Reddit
https://www.reddit.com/r/ethereum/comments/eca9i5/how_tun_run_an_ethereum_node_over_tor_and_why/
[32] [33] [34] [35] [36] [37] Configuring Tor | Builder's Guide
https://docs.lightning.engineering/lightning-network-tools/lnd/configuring_tor
[38] [39] [40] [41] [42] [43] Tor Support in Zcash — Zcash Documentation 6.10.0 documentation
https://zcash.readthedocs.io/en/master/rtd_pages/tor.html
[44] grin_wallet_util - Rust - Docs.rs
https://docs.rs/grin_wallet_util
[53] TC: A Tor control protocol (Version 1) - GitLab
https://torproject.gitlab.io/torspec/control-spec/
[55] [56] [58] [59] [60] [61] [62] [70] 351-socks-auth-extensions - Tor design proposals
https://spec.torproject.org/proposals/351-socks-auth-extensions.html
[57] tor(1): second-generation onion router - Linux man page
https://linux.die.net/man/1/tor
[63] [79] [82] [83] [84] [85] Bitcoin over Tor isn't a Good Idea
https://www.ieee-security.org/TC/SP2015/papers-archived/6949a122.pdf
[64] Tor/VPN Questions - Delta.Chat
https://support.delta.chat/t/tor-vpn-questions/2955
[73] tor-hscrypto - crates.io: Rust Package Registry
https://crates.io/crates/tor-hscrypto
[74] torut::onion - Rust - Docs.rs
https://docs.rs/torut/latest/torut/onion/
[75] libp2p::core::multiaddr - Rust
https://tidelabs.github.io/tidechain/libp2p/core/multiaddr/index.html
[76] Anonymous peer to peer applications in Rust (rust-libp2p over Tor)
https://comit.network/blog/2020/07/02/tor-poc/
[88] Changelog - Kube.rs
https://kube.rs/changelog/
[89] tor_hsservice - Rust - The Tor Project's Gitlab
https://tpo.pages.torproject.net/core/doc/rust/tor_hsservice/index.html
